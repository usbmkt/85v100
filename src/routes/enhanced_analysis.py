#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v2.0 - Enhanced Analysis Route CORRIGIDA
Rota principal para an√°lise aprimorada - FUNCIONANDO
"""

from flask import Blueprint, request, jsonify
import logging
import time
import uuid
from datetime import datetime
from services.auto_save_manager import salvar_etapa, salvar_erro
from services.unified_search_manager import unified_search_manager
from services.robust_content_extractor import robust_content_extractor
from services.mcp_supadata_manager import mcp_supadata_manager
from services.ai_manager import ai_manager

logger = logging.getLogger(__name__)

enhanced_analysis_bp = Blueprint('enhanced_analysis', __name__)

@enhanced_analysis_bp.route('/analyze_ultra_enhanced', methods=['POST'])
def analyze_ultra_enhanced():
    """Endpoint principal para an√°lise ultra aprimorada CORRIGIDA"""

    session_id = f"enhanced_{int(time.time() * 1000)}_{uuid.uuid4().hex[:8]}"

    try:
        # Recebe dados do formul√°rio
        form_data = request.get_json() if request.is_json else request.form.to_dict()

        logger.info(f"üöÄ INICIANDO AN√ÅLISE REAL: {session_id}")
        salvar_etapa('analise_iniciada', {
            'session_id': session_id,
            'form_data': form_data,
            'timestamp': datetime.now().isoformat()
        }, categoria="analise_completa")

        # Extrai informa√ß√µes do formul√°rio
        segmento = form_data.get('segmento', '')
        produto = form_data.get('produto', '')
        publico = form_data.get('publico', '')

        if not all([segmento, produto, publico]):
            return jsonify({
                'success': False,
                'error': 'Campos obrigat√≥rios n√£o preenchidos',
                'session_id': session_id
            }), 400

        # Constr√≥i contexto da an√°lise
        context = {
            'segmento': segmento,
            'produto': produto,
            'publico': publico,
            'preco': form_data.get('preco'),
            'objetivo_receita': form_data.get('objetivo_receita'),
            'orcamento_marketing': form_data.get('orcamento_marketing'),
            'prazo_lancamento': form_data.get('prazo_lancamento'),
            'concorrentes': form_data.get('concorrentes'),
            'dados_adicionais': form_data.get('dados_adicionais')
        }

        # Query principal para busca
        main_query = f"{segmento} {produto} {publico} mercado brasileiro"

        logger.info(f"üìä Iniciando an√°lise para: {main_query}")

        # 1. COLETA MASSIVA DE DADOS
        logger.info("üåê EXECUTANDO COLETA MASSIVA DE DADOS...")
        supadata_result = mcp_supadata_manager.collect_massive_data(
            query=main_query,
            context=context,
            depth_level=3
        )

        salvar_etapa('supadata_coletado', supadata_result, categoria="analise_completa")

        # 2. AN√ÅLISE ESPEC√çFICA DO MERCADO
        logger.info("üìà EXECUTANDO AN√ÅLISE ESPEC√çFICA DO MERCADO...")
        market_search = unified_search_manager.unified_search(
            query=f"{segmento} an√°lise mercado brasileiro tend√™ncias 2024",
            max_results=15,
            context=context,
            session_id=session_id
        )

        salvar_etapa('busca_mercado', market_search, categoria="analise_completa")

        # 3. AN√ÅLISE DO P√öBLICO-ALVO
        logger.info("üë• EXECUTANDO AN√ÅLISE DO P√öBLICO-ALVO...")
        audience_search = unified_search_manager.unified_search(
            query=f"{publico} comportamento consumo {segmento} Brasil",
            max_results=10,
            context=context,
            session_id=session_id
        )

        salvar_etapa('busca_publico', audience_search, categoria="analise_completa")

        # 4. AN√ÅLISE DA CONCORR√äNCIA
        logger.info("‚öîÔ∏è EXECUTANDO AN√ÅLISE DA CONCORR√äNCIA...")
        competition_query = f"{produto} concorrentes {segmento} Brasil"
        if context.get('concorrentes'):
            competition_query += f" {context['concorrentes']}"

        competition_search = unified_search_manager.unified_search(
            query=competition_query,
            max_results=12,
            context=context,
            session_id=session_id
        )

        salvar_etapa('busca_concorrencia', competition_search, categoria="analise_completa")

        # 5. EXTRA√á√ÉO DE CONTE√öDO DAS PRINCIPAIS FONTES
        logger.info("üìÑ EXTRAINDO CONTE√öDO DAS PRINCIPAIS FONTES...")
        extracted_contents = []

        # Combina resultados de todas as buscas
        all_search_results = []
        all_search_results.extend(market_search.get('results', [])[:5])
        all_search_results.extend(audience_search.get('results', [])[:3])
        all_search_results.extend(competition_search.get('results', [])[:4])

        for i, result in enumerate(all_search_results):
            try:
                url = result.get('url', '')
                logger.info(f"üìñ Extraindo {i+1}/{len(all_search_results)}: {result.get('title', 'Sem t√≠tulo')}")

                content, metadata = robust_content_extractor.extract_content(url)
                if content and len(content) > 300:
                    extracted_contents.append({
                        'url': url,
                        'title': result.get('title', ''),
                        'content': content,
                        'source_type': 'market_research'
                    })

                time.sleep(0.5)  # Rate limiting

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao extrair {url}: {e}")
                continue

        salvar_etapa('conteudo_extraido', {
            'total_extracted': len(extracted_contents),
            'contents': extracted_contents
        }, categoria="analise_completa")

        # 6. AN√ÅLISE FINAL COM IA
        logger.info("üß† EXECUTANDO AN√ÅLISE FINAL COM IA...")

        # Combina todo o conte√∫do para an√°lise
        combined_analysis_content = ""

        # Adiciona dados do SupaData
        if supadata_result.get('intelligent_analysis', {}).get('ai_analysis'):
            combined_analysis_content += f"AN√ÅLISE SUPADATA:\n{supadata_result['intelligent_analysis']['ai_analysis']}\n\n"

        # Adiciona conte√∫do extra√≠do
        for content_item in extracted_contents[:8]:  # Top 8 conte√∫dos
            combined_analysis_content += f"FONTE: {content_item['title']}\n"
            combined_analysis_content += content_item['content'][:2000] + "\n\n"

        # Prompt para an√°lise final
        final_analysis_prompt = f"""
        AN√ÅLISE ULTRA-DETALHADA DE MERCADO - ARQV30 ENHANCED

        DADOS DO NEG√ìCIO:
        - Segmento: {segmento}
        - Produto/Servi√ßo: {produto}  
        - P√∫blico-Alvo: {publico}
        - Pre√ßo: {context.get('preco', 'N/A')}
        - Objetivo de Receita: {context.get('objetivo_receita', 'N/A')}
        - Or√ßamento Marketing: {context.get('orcamento_marketing', 'N/A')}
        - Prazo Lan√ßamento: {context.get('prazo_lancamento', 'N/A')}
        - Concorrentes: {context.get('concorrentes', 'N/A')}

        DADOS COLETADOS DA WEB:
        {combined_analysis_content}

        TAREFA:
        Gere uma an√°lise ULTRA-DETALHADA e COMPLETA incluindo:

        1. AN√ÅLISE DE MERCADO PROFUNDA
        - Tamanho do mercado e potencial
        - Tend√™ncias identificadas
        - Oportunidades espec√≠ficas

        2. AN√ÅLISE DO P√öBLICO-ALVO
        - Perfil comportamental detalhado
        - Dores e necessidades espec√≠ficas
        - Canais de comunica√ß√£o preferenciais

        3. AN√ÅLISE COMPETITIVA COMPLETA
        - Principais concorrentes identificados
        - Pontos fortes e fracos da concorr√™ncia
        - Oportunidades de diferencia√ß√£o

        4. ESTRAT√âGIA DE POSICIONAMENTO
        - Proposta de valor √∫nica
        - Messaging framework
        - Diferencia√ß√£o competitiva

        5. ESTRAT√âGIA DE MARKETING
        - Canais de aquisi√ß√£o recomendados
        - Estrat√©gia de conte√∫do
        - Cronograma de lan√ßamento

        6. PROJE√á√ïES E M√âTRICAS
        - Estimativas de convers√£o
        - Proje√ß√µes de receita
        - KPIs recomendados

        7. PLANO DE A√á√ÉO DETALHADO
        - Pr√≥ximos passos espec√≠ficos
        - Timeline de implementa√ß√£o
        - Recursos necess√°rios

        Baseie-se EXCLUSIVAMENTE nos dados coletados e forne√ßa uma an√°lise pr√°tica, acion√°vel e extremamente detalhada.
        """

        final_analysis = ai_manager.generate_content(
            prompt=final_analysis_prompt,
            max_tokens=4000,
            temperature=0.2
        )

        salvar_etapa('analise_final_ia', {
            'analysis': final_analysis,
            'prompt_length': len(final_analysis_prompt),
            'response_length': len(final_analysis)
        }, categoria="analise_completa")

        # 7. COMPILA RESULTADO FINAL
        final_result = {
            'success': True,
            'session_id': session_id,
            'analysis_timestamp': datetime.now().isoformat(),
            'input_data': context,
            'data_collection': {
                'supadata_results': supadata_result.get('statistics', {}),
                'web_searches_performed': 3,  # Market, Audience, Competition
                'content_sources_extracted': len(extracted_contents),
                'total_data_quality_score': supadata_result.get('supadata_collection', {}).get('data_quality_score', 0)
            },
            'final_analysis': final_analysis,
            'supporting_data': {
                'market_search_results': len(market_search.get('results', [])),
                'audience_search_results': len(audience_search.get('results', [])),
                'competition_search_results': len(competition_search.get('results', [])),
                'extracted_content_sources': [
                    {'title': c['title'], 'url': c['url']} 
                    for c in extracted_contents
                ]
            },
            'metadata': {
                'analysis_engine': 'ARQV30_Enhanced_v2_REAL',
                'webscraping_performed': True,
                'supadata_used': True,
                'content_extraction_performed': True,
                'ai_analysis_performed': True
            }
        }

        salvar_etapa('resultado_final_completo', final_result, categoria="analise_completa")

        logger.info(f"‚úÖ AN√ÅLISE REAL CONCLU√çDA: {session_id}")

        return jsonify(final_result)

    except Exception as e:
        logger.error(f"‚ùå ERRO CR√çTICO na an√°lise {session_id}: {str(e)}", exc_info=True)

        salvar_erro('analise_critica', e, contexto={
            'session_id': session_id,
            'form_data': form_data if 'form_data' in locals() else {}
        })

        return jsonify({
            'success': False,
            'error': f'Erro cr√≠tico na an√°lise: {str(e)}',
            'session_id': session_id,
            'timestamp': datetime.now().isoformat()
        }), 500

@enhanced_analysis_bp.route('/status/<session_id>', methods=['GET'])
def get_analysis_status(session_id):
    """Retorna status de uma an√°lise espec√≠fica"""

    try:
        # Status b√°sico - poderia ser expandido com sistema de cache
        return jsonify({
            'session_id': session_id,
            'status': 'completed',  # Por simplicidade, sempre completed
            'timestamp': datetime.now().isoformat(),
            'systems_status': {
                'unified_search': unified_search_manager.get_provider_status(),
                'content_extractor': robust_content_extractor.get_stats(),
                'supadata_manager': mcp_supadata_manager.get_status(),
                'ai_manager': ai_manager.get_provider_status()
            }
        })

    except Exception as e:
        logger.error(f"‚ùå Erro ao obter status {session_id}: {e}")
        return jsonify({
            'error': str(e),
            'session_id': session_id
        }), 500