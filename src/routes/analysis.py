#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v2.0 - Rotas de An√°lise
Sistema completo de an√°lise de mercado com agentes especializados
"""

import logging
from flask import Blueprint, render_template, request, jsonify
from services.ultra_detailed_analysis_engine import ultra_analysis_engine
from services.enhanced_ui_manager import enhanced_ui_manager
from services.context_intelligence_engine import context_intelligence_engine
from services.professional_report_manager import professional_report_manager
import traceback
import uuid
import time
from datetime import datetime

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Blueprint para an√°lises
analysis_bp = Blueprint('analysis', __name__)

@analysis_bp.route('/')
def index():
    """P√°gina principal com interface aprimorada"""
    try:
        return render_template('enhanced_interface.html')
    except Exception as e:
        logger.error(f"Erro ao carregar interface: {e}")
        return render_template('enhanced_interface.html')

@analysis_bp.route('/api/analyze', methods=['POST'])
def analyze():
    """Rota principal para an√°lise"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
            
        # Valida√ß√£o b√°sica
        if not data.get('segmento'):
            return jsonify({
                'success': False,
                'error': 'Segmento √© obrigat√≥rio'
            }), 400
            
        # Gera ID √∫nico para a an√°lise
        analysis_id = f"analysis_{int(time.time() * 1000)}_{uuid.uuid4().hex[:8]}"
        
        # Executa an√°lise usando o motor ultra-detalhado
        result = ultra_analysis_engine.generate_comprehensive_analysis(
            data, analysis_id
        )
        
        return jsonify({
            'success': True,
            'analysis_id': analysis_id,
            'data': result
        })
        
    except Exception as e:
        logger.error(f"Erro na an√°lise: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# Fun√ß√£o get_progress removida - usando sistema de progresso centralizado

@analysis_bp.route('/api/get_analysis_result/<task_id>', methods=['GET'])
def get_analysis_result(task_id):
    """Obt√©m resultado da an√°lise"""
    try:
        # Por enquanto, retorna dados simulados
        # No futuro, pode consultar resultados salvos
        return jsonify({
            'success': True,
            'task_id': task_id,
            'data': {
                'avatar_ultra_detalhado': {
                    'nome': 'Avatar Profissional',
                    'dores': ['Falta de tempo', 'Necessidade de resultados'],
                    'desejos': ['Efici√™ncia', 'Sucesso profissional']
                },
                'drivers_mentais_customizados': [
                    {'nome': 'Driver Urg√™ncia', 'descri√ß√£o': 'Cria senso de urg√™ncia'},
                    {'nome': 'Driver Autoridade', 'descri√ß√£o': 'Estabelece credibilidade'}
                ]
            }
        })
    except Exception as e:
        logger.error(f"Erro ao obter resultado: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@analysis_bp.route('/api/list_local_analyses', methods=['GET'])
def list_local_analyses():
    """Lista an√°lises locais"""
    try:
        # Por enquanto, retorna lista vazia
        # No futuro, pode consultar an√°lises salvas
        return jsonify({
            'success': True,
            'analyses': []
        })
    except Exception as e:
        logger.error(f"Erro ao listar an√°lises: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@analysis_bp.route('/api/app_status', methods=['GET'])
def app_status():
    """Status da aplica√ß√£o"""
    try:
        return jsonify({
            'success': True,
            'status': 'operational',
            'services': {
                'search_providers': {'available': 1},
                'ai_providers': {'available': 1}
            }
        })
    except Exception as e:
        logger.error(f"Erro ao obter status: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@analysis_bp.route('/api/get_agent_capabilities', methods=['GET'])
def get_agent_capabilities():
    """Capacidades dos agentes"""
    try:
        return jsonify({
            'success': True,
            'capabilities': {
                'web_research': {'status': 'operational', 'description': 'Pesquisa web avan√ßada'},
                'ai_analysis': {'status': 'operational', 'description': 'An√°lise com IA'},
                'report_generation': {'status': 'operational', 'description': 'Gera√ß√£o de relat√≥rios'}
            }
        })
    except Exception as e:
        logger.error(f"Erro ao obter capacidades: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@analysis_bp.route('/api/start_enhanced_analysis', methods=['POST'])
def start_enhanced_analysis():
    """Endpoint para iniciar an√°lise enhanced"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'Dados n√£o fornecidos'
            }), 400
            
        # Valida√ß√£o
        if not data.get('segmento'):
            return jsonify({
                'success': False,
                'error': 'Segmento √© obrigat√≥rio'
            }), 400
            
        # ID da tarefa
        task_id = f"enhanced_{int(time.time() * 1000)}_{uuid.uuid4().hex[:8]}"
        
        logger.info(f"üöÄ Iniciando an√°lise enhanced: {task_id}")
        
        # Executa an√°lise (pode ser ass√≠ncrona no futuro)
        result = ultra_analysis_engine.generate_comprehensive_analysis(
            data, task_id
        )
        
        return jsonify({
            'success': True,
            'task_id': task_id,
            'message': 'An√°lise iniciada com sucesso',
            'data': result
        })
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao iniciar an√°lise enhanced: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'message': 'Erro ao iniciar an√°lise'
        }), 500

@analysis_bp.route('/api/analyze', methods=['POST'])
def start_analysis():
    """Inicia an√°lise ultra-detalhada"""
    try:
        data = request.get_json()

        if not data:
            return jsonify({
                'success': False,
                'message': 'Dados n√£o fornecidos'
            }), 400

        # Valida√ß√µes essenciais
        if not data.get('segmento'):
            return jsonify({
                'success': False,
                'message': 'Segmento de mercado √© obrigat√≥rio'
            }), 400

        # Gera ID da sess√£o
        session_id = f"session_{int(time.time() * 1000)}_{uuid.uuid4().hex[:12]}"

        logger.info(f"üéØ Iniciando an√°lise para sess√£o: {session_id}")
        logger.info(f"üìä Segmento: {data.get('segmento')}")
        logger.info(f"üéÅ Produto: {data.get('produto', 'N/A')}")

        # Executa an√°lise real usando o engine dispon√≠vel
        try:
            from services.ultra_detailed_analysis_engine import ultra_analysis_engine
            
            # Executa an√°lise completa
            resultado_analise = ultra_analysis_engine.generate_gigantic_analysis(
                data, session_id
            )

            # Salva no banco automaticamente
            from database import db_manager
            try:
                db_record = db_manager.create_analysis({
                    **data,
                    **resultado_analise,
                    'analysis_type': 'ultra_detailed',
                    'session_id': session_id,
                    'status': 'completed'
                })
                if db_record:
                    resultado_analise['database_id'] = db_record.get('id')
                    logger.info(f"‚úÖ An√°lise salva no banco: ID {db_record.get('id')}")
            except Exception as db_error:
                logger.warning(f"‚ö†Ô∏è Erro ao salvar no banco: {db_error}")

            return jsonify({
                'success': True,
                'message': 'An√°lise conclu√≠da com sucesso',
                'session_id': session_id,
                'data': resultado_analise
            })

        except Exception as analysis_error:
            logger.error(f"‚ùå Erro ao executar an√°lise: {analysis_error}")
            return jsonify({
                'success': False,
                'message': f'Erro na an√°lise: {str(analysis_error)}'
            }), 500

    except Exception as e:
        logger.error(f"‚ùå Erro geral na rota de an√°lise: {e}")
        logger.error(traceback.format_exc())

        return jsonify({
            'success': False,
            'error': 'internal_server_error',
            'message': 'Erro interno do servidor',
            'details': str(e) if logger.level <= logging.DEBUG else None
        }), 500

# Segunda fun√ß√£o get_progress removida - usando sistema de progresso centralizado

@analysis_bp.route('/api/save_analysis', methods=['POST'])
def save_analysis():
    """Salva an√°lise no banco de dados"""
    try:
        data = request.get_json()
        session_id = data.get('session_id')

        if not session_id:
            return jsonify({
                'success': False,
                'message': 'ID da sess√£o n√£o fornecido'
            }), 400

        # Obt√©m dados da an√°lise
        try:
            # Tenta executar an√°lise se n√£o existe
            from services.auto_save_manager import auto_save_manager
            etapas_salvas = auto_save_manager.listar_etapas_salvas(session_id)

            if not etapas_salvas:
                # Executa an√°lise se n√£o foi executada ainda
                dados_entrada = {
                    'segmento': 'an√°lise solicitada',
                    'session_id': session_id
                }
                resultado_analise = ultra_analysis_engine.generate_gigantic_analysis(dados_entrada, session_id)

        except Exception as e:
            logger.warning(f"N√£o foi poss√≠vel executar an√°lise: {e}")

        # Busca progresso nos relat√≥rios salvos
        from services.auto_save_manager import auto_save_manager
        etapas_salvas = auto_save_manager.listar_etapas_salvas(session_id)

        analysis_data = {}
        if etapas_salvas:
            for etapa_nome in etapas_salvas.keys():
                dados_etapa = auto_save_manager.recuperar_etapa(etapa_nome, session_id)
                if dados_etapa and dados_etapa.get('status') == 'sucesso':
                    analysis_data[etapa_nome] = dados_etapa.get('dados')

        progress = {
            'status': 'completed' if analysis_data else 'in_progress',
            'data': analysis_data,
            'session_id': session_id
        }

        if not progress or progress.get('status') != 'completed':
            return jsonify({
                'success': False,
                'message': 'An√°lise n√£o est√° completa'
            }), 400

        # Salva no banco (implementar conforme necess√°rio)
        success = professional_report_manager.save_analysis_to_database(
            session_id, 
            progress.get('data', {})
        )

        if success:
            return jsonify({
                'success': True,
                'message': 'An√°lise salva com sucesso'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'Erro ao salvar an√°lise'
            }), 500

    except Exception as e:
        logger.error(f"‚ùå Erro ao salvar an√°lise: {e}")
        return jsonify({
            'success': False,
            'message': 'Erro interno do servidor'
        }), 500

@analysis_bp.route('/archaeological')
def archaeological_interface():
    """Interface arqueol√≥gica especializada"""
    try:
        return render_template('archaeological_interface.html')
    except Exception as e:
        logger.error(f"Erro ao carregar interface arqueol√≥gica: {e}")
        return render_template('enhanced_interface.html')

@analysis_bp.route('/forensic')  
def forensic_interface():
    """Interface forense especializada"""
    try:
        return render_template('forensic_interface.html')
    except Exception as e:
        logger.error(f"Erro ao carregar interface forense: {e}")
        return render_template('enhanced_interface.html')

@analysis_bp.route('/api/render_analysis/<session_id>')
def render_analysis_results(session_id):
    """Renderiza resultados da an√°lise com UI aprimorada"""
    try:
        # Busca progresso nos relat√≥rios salvos
        from services.auto_save_manager import auto_save_manager
        etapas_salvas = auto_save_manager.listar_etapas_salvas(session_id)

        analysis_data = {}
        if etapas_salvas:
            for etapa_nome in etapas_salvas.keys():
                dados_etapa = auto_save_manager.recuperar_etapa(etapa_nome, session_id)
                if dados_etapa and dados_etapa.get('status') == 'sucesso':
                    analysis_data[etapa_nome] = dados_etapa.get('dados')

        progress = {
            'status': 'completed' if analysis_data else 'in_progress',
            'data': analysis_data,
            'session_id': session_id
        }


        if not progress or progress.get('status') != 'completed':
            return jsonify({
                'success': False,
                'message': 'An√°lise n√£o encontrada ou incompleta'
            }), 404

        analysis_data = progress.get('data', {})

        # Renderiza componentes com UI manager
        rendered_components = {}

        # Avatar visceral
        if 'avatar_visceral_ultra' in analysis_data:
            rendered_components['avatar'] = enhanced_ui_manager.render_visceral_avatar(
                analysis_data
            )

        # Drivers mentais
        if 'drivers_mentais_customizados' in analysis_data:
            rendered_components['drivers'] = enhanced_ui_manager.render_drivers_arsenal(
                analysis_data.get('drivers_mentais_customizados', {})
            )

        # Provas visuais
        if 'provas_visuais_sugeridas' in analysis_data:
            rendered_components['provas'] = enhanced_ui_manager.render_provis_arsenal(
                analysis_data.get('provas_visuais_sugeridas', {})
            )

        # M√©tricas forenses
        if 'metricas_forenses' in analysis_data:
            rendered_components['metricas'] = enhanced_ui_manager.render_forensic_metrics(
                analysis_data.get('metricas_forenses', {})
            )

        return jsonify({
            'success': True,
            'components': rendered_components,
            'metadata': {
                'session_id': session_id,
                'timestamp': analysis_data.get('timestamp'),
                'segmento': analysis_data.get('segmento'),
                'produto': analysis_data.get('produto')
            }
        })

    except Exception as e:
        logger.error(f"‚ùå Erro ao renderizar an√°lise: {e}")
        return jsonify({
            'success': False,
            'message': 'Erro ao renderizar resultados'
        }), 500

# Handlers de erro
@analysis_bp.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'message': 'Endpoint n√£o encontrado'
    }), 404

@analysis_bp.errorhandler(500)
def internal_error(error):
    logger.error(f"‚ùå Erro interno do servidor: {error}")
    return jsonify({
        'success': False,
        'message': 'Erro interno do servidor'
    }), 500

# Registro das rotas
logger.info("‚úÖ Rotas de an√°lise registradas com sucesso")